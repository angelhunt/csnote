不太懂，我现在都是sigmoid + binary cross entropy来做问题已关注，希望有大神来埋坑！可以关注一下Pytorch MultiLabel给的Loss发现Paperwithcode上有一个任务就是Multilabel classification。里面一堆文章https://paperswithcode.com/task/multi-label-classification​paperswithcode.com/task/multi-label-classification主要是优化Papers with Code - Multi-Label Classification主要是优化任务之间的相关性改善长尾分布改善二分类时候正负样本不平衡的问题

作者：铁蛋
链接：https://www.zhihu.com/question/422946096/answer/1495483730
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。


https://www.zhihu.com/question/422946096/answers/updated

现在遇到 MLL task, 第一个想到的就是 DNN + binary cross entropy loss.

在 Bing Search Engine 中, MS 把用户键入的 query 作为一个 label, 而每个搜有页面下方展示的 related searches 是用 MLL 算法推荐的


# 优化器 
梯度是一个随机变量，一阶矩表示梯度均值，二阶矩表示其方差，一阶矩来控制模型更新的方向，二阶矩控制步长(学习率)。用moveing average来对一阶矩和二阶矩进行估计。偏差修正是为了缓解初始一阶矩和二阶矩初始为0带来的moving average的影响。

https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c

for t in range(num_iterations):
    g = compute_gradient(x, y)
    m = beta_1 * m + (1 - beta_1) * g
    # 偏差修正
    m_hat = m / (1 - np.power(beta_1, t))
    v = np.maximum(beta_2 * v, np.abs(g))
    w = w - step_size * m_hat / v


# tmux
https://blog.csdn.net/liumiaocn/article/details/104100000
