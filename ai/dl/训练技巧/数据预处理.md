# 数据倾斜
逻辑回归的输出范围为[0,1]]，当某个样本的输出大于0.5就会被划分为正例.
在数据的类别不平衡时，采用默认的分类阈值可能会导致输出全部为反例，
产生虚假的高准确度，导致分类失败。

1. 可以选择调整阈值，使得模型对于较少的类别更为敏感
2. 选择合适的评估标准，比如ROC或者F1，而不是准确度（accuracy）

所以遇到不平衡数据，用集成学习+阈值调整可以作为第一步尝试。

而通过采样（sampling）来调整数据的不平衡，是另一种解决途径，并且可以和阈值调整同时使用。而采样法最受人诟病的就是可能会改变原始数据的分布，从而带来偏差。

数据不平衡会影响损失函数（模型容易忽略占比很少的实例）, 模型评估指标.
许多模型的输出类别是基于阈值的，例如逻辑回归中小于0.5的为反例，大于则为正例。在数据不平衡时，默认的阈值会导致模型输出倾向与类别数据多的类别。

2）选择合适的评估标准，比如ROC，AUC或者F1,G-mean，而不是准确度（accuracy）

阈值调整（threshold moving），将原本默认为0.5的阈值调整到 较少类别/（较少类别+较多类别）即可



3）过采样法（sampling）：来处理不平横的问题。分为欠采样(undersampling)和过采样(oversampling)两种，

过采样：重复正比例数据，实际上没有为模型引入更多数据，过分强调正比例数据，会放大正比例噪音对模型的影响。

欠采样：丢弃大量数据，和过采样一样会存在过拟合的问题。
欠采样的逻辑中往往会结合集成学习来有效的使用数据，假设正例数据n，而反例数据m个。我们可以通过欠采样，随机无重复的生成（k=n/m）个反例子集，并将每个子集都与相同正例数据合并生成k个新的训练样本。我们在k个训练样本上分别训练一个分类器，最终将k个分类器的结果结合起来，比如求平均值。这就是一个简单的思路，也就是Easy Ensemble


由于随机过采样采取简单复制样本的策略来增加少数类样本，这样容易产生模型过拟合的问题，即使得模型学习到的信息过于特别(Specific)而不够泛化(General)

数据合成：SMOTE（Synthetic Minority Oversampling Technique）即合成少数类过采样技术，它是基于随机过采样算法的一种改进方案，SMOTE算法的基本思想是对少数类样本进行分析并根据少数类样本人工插值合成新样本

z从算法角度
选择对数据倾斜相对不敏感的算法。如树模型等。


将任务转换成异常检测问题。譬如有这样一个项目，需要从高压线的航拍图片中，将松动的螺丝/零件判断为待检测站点，即负样本，其他作为正样本，这样来看，数据倾斜是非常严重的，而且在图像质量一般的情况下小物体检测的难度较大，所以不如将其转换为无监督的异常检测算法，不用过多的去考虑将数据转换为平衡问题来解决。

过拟合最直观的表现就是 training accuracy 特别高，但是testing accuracy 特别低，即两者相差特别大。



于很多知识和能力有限的人来说难度比较大。特此推荐两个简单易行且效果中上的做法：

简单的调整阈值，不对数据进行任何处理。此处特指将分类阈值从0.5调整到正例比例
使用现有的集成学习分类器，如随机森林或者xgboost，并调整分类阈值


https://zhuanlan.zhihu.com/p/32940093


严重数据倾斜文本分类，比如正反比1:20～100，适合什么model，查准一般要做到多少可以上线？ - 微调的回答 - 知乎
https://www.zhihu.com/question/59236897/answer/500338632

欠采样（undersampling）和过采样（oversampling）会对模型带来怎样的影响？ - 微调的回答 - 知乎
https://www.zhihu.com/question/269698662/answer/352279936

