CUDA，tensorRT和deepstream。

TensorRT Inference Server。当时的版本提供以下超赞的功能：

支持单GPU上的多模型&单模型多实例支持多种backends框架（TensorRT、Tensorflow）动态Batch增加吞吐提供负载均衡及状态监测.
Parallel Reduction 算法.~


    你的编程能力从什么时候开始突飞猛进？ - 李rumor的回答 - 知乎
https://www.zhihu.com/question/356351510/answer/1688320529