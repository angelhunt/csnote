# 比赛

https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%B7%A5%E4%B8%9A%E7%95%8C.md#222-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0

https://posts.careerengine.us/p/5f0b03ec13dd372a63c5252e

https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%B7%A5%E4%B8%9A%E7%95%8C.md#22-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0



# pipeline方法




# 统计模型监督学习
标准流程：

预先定义提取的关系集合
选择相关命名实体集合
寻找并标注数据
选择有代表性的语料库
标记命名实体
人工标注实体间关系
分割训练、开发、测试集
设计特征
选择并训练分类器
评估结果

训练一个关系抽取器，换句话讲就是训练一个关系分类器.需要人工的标注好语料，基于语料库我们一共有多少种关系.
当模型训练好了之后，给它一个包含两个实体的句子，我们通过特征提取生成一个句子向量，通过根据语料数据训练出的关系抽取器来判定该句子应当分到哪一类中去，从而完成句子中两实体的关系分类。

命名实体识别跟之前的类似, 识别出实体之后，需要根据实体学习两两之间的关系.

通常会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。
常用的分类器包括 MaxEnt、Naive Bayes、SVM 等。

## 特征提取

Lexical features
1. 实体对之间的词串;

2. 这些词的词性标记;

3. 哪个实体出现在前;

4. 实体1左边k个词和它们的POS标记;

5. 实体2右边k个词和它们的POS标记。


常见特征：

实体特征，包括实体前后的词，实体类型，实体之间的距离等

chunk，如 NP，VP，PP 这类短语

实体间的依存关系，实体间树结构的距离，及其他特定的结构信息

https://github.com/KavinKKuppusamy/NLP-Classifying-Semantic-Relation-between-Entities-using-LinearSVM


# 代码
https://github.com/KavinKKuppusamy/NLP-Classifying-Semantic-Relation-between-Entities-using-LinearSVM

https://github.com/roomylee/awesome-relation-extraction

https://github.com/yuanxiaosc/Entity-Relation-Extraction


# 问题

对于大量噪声数据的过滤的研究也一直在进行中，例如使用Multi-instance从训练集中抽取取置信度高的训练样例训练模型，利用Attention模型对数据进行全方位的权重计算，从而得到全面而不失“选择”的训练数据。对于错误传播放大的问题近期更有“joint learning”方法的提出，将命名实体识别和关系抽取两部并为一步走。原本流水线（pipeline ）式的方法也是人为的将一个句子的信息抽取分成两部走，现在这种更加“原生态”的关系抽取方式说不定能够大放异彩。
