项目目标

总共有几百个VC, 十几万个job每天。存储所有365, teams等的数据。
实际上已经有很多数据库安全监控，


monitor health of a cluster(CPU and memory usage)
detect  security  threats, intrusion detection
perform  user activity monitoring

已经有很多安全手段，重要的数据可以通过访问控制保护，但是这些机制无法判断用户是否执行有害的操作（例如提交大量的Job, 类似于flood攻击)

1. 系统支持定义规则和策略，例如当某项指标超限就发邮件/电话（但是缺点是无法定义所有的规则，阈值也很难决定）
2. 因此也要支持基于ml的异常检测

collects audit logs from Hadoop clusters and applications running on them, analyzes users behavior, generates profiles per user of the system, and predicts anomalous user activities based on their prior profiles

Imperva [7] is a mature product that supports database activity monitoring by setting up rules and policies

# 安全机制

![](pic/2FA%20authentication%20technique,%20complicated%20authorizations,%20and%20hierarchical%20access%20control%20policy%20management.png)

# 基于ml的用户异常行为检测

每个个人用户都可以提交job, 也有所有的team账号提交job.

大概步骤由下面组成

1. cosmos event log采集输出，生成每个用户的用户画像，其中包含每天提交的job数据，读取的数据量等。
2. 提起user profile，并进行模型离线训练
3. 实时检测用户行为时，使用消息队列存储需要处理的活动事件，系统将活动事件跟历史的用户画像进行匹配，判断用户是否执行有害操作。
4. 检测到异常以后，发送alert到alert engine， 会进行报警合并

特征提取包括下面
1. 用户统计信息，比如ip地址,访问存储的时间
2. 用户活动信息，比如当天提交的job数量和频率，存储访问频率（hourly, daily, weekly）

这个系统中离线训练用于生成用户画像.
我们使用了PCA和Density Estimation两种算法。

## PCA
user profile generation is to find interesting behavioral patterns for users. 

One way to achieve that goal is to consider combination of features and see how each one influences the other.

As normal behavioral patterns can lie within very low-dimensional subspace, shown by Lakhina et al. [18], we can potentially reduce the dimension of the dataset to better understand user behavioral pattern. This method also reduces noise.

总共提取了15个特征。
用户的行为模式通常体现在低维空间，因此我们需要捕获到最关键的特征组合，并且这些特征组合能够很好的，反应用户的行为模式。

这里使用用户的时序行为作为输入，可以表示为T*d的矩阵，每一行都是一个时间步。
我们需要对整个区间进行PCA特征变换，将用户历史行为压缩到一个主成分空间（主成分向量都代表了方差变换最大的方向）。

因为数据统计起来的方差，大概是85%，因此我们需要找到合适的k，能够包含85的方差.

The remaining (n-k) principal components are considered as abnormal subspace.因为数据基本都在主成分方向变化，在非主成分方向变化说明出现了问题。（当然也需要衡量。
训练完成我们需要将主成分保存下来。事实预测的时候需要用到。

PCA提取完主成分后，可以考虑下面的思路进行detection
1. 计算每个样本再经过这k个特征向量投射后的重建误差，跟正常样本比过大说明异常
2. 计算每个样本到这k个选特征向量所构成的超空间的加权欧氏距离（特征值越小权重越大）
3. 把样本的马氏距离（在考虑特征间关系时样本到分布中心的距离）作为样本的异常度,而这种方法也可以被理解为一种软性（Soft PCA）


https://zhuanlan.zhihu.com/p/48110105


# 异常检测知识点

做embedding，之后再用异常检测的算法。或者，有些异常检测算法本身就是和embedding融合的。Google搜这两个关键词组合就有，我记得看过一篇用GMM+AE框架的。



# 集群检测

有很多的集群衡量指标，

 # eagle
 i

## User Profile Machine Learning

define user activity patterns or user profiles for Apache Hadoop users based on the user behavior in the platform。
The idea is to provide anomaly detection capability without setting hard thresholds in the system。

The user profiles generated by our system are modeled using machine-learning algorithms and used for detection of anomalous user activities, where users’ activity pattern differs from their pattern history. 

 Currently Eagle uses two algorithms for anomaly detection: Eigen-Value Decomposition and Density Estimation. The algorithms read data from HDFS audit logs, slice and dice data, and generate models for each user in the system.
 
 Once models are generated, Eagle uses the Apache Storm framework for near-real-time anomaly detection to determine if current user activities are suspicious or not with respect to their model. The block diagram below shows the current pipeline for user profile training and online detection.

